# （24 TSC）ELXGB_An_Efficient_and_Privacy-Preserving_XGBoost_for_Vertical_Federated_Learning 
 ## 全文摘要 
###  
本文介绍了一种名为ELXGB的高效隐私保护垂直联邦学习框架，该框架基于XGBoost算法，旨在解决传统联邦学习中数据隔离和相关法规的限制问题。为了保证安全性和效率性，作者设计了两个节点分裂算法，利用同态加密和差分隐私技术实现了树节点的生成和全局模型的构建；同时，使用属性混淆和方向混淆等技术实现了安全的推理算法，避免敏感信息泄漏并保护全局模型。实验结果表明，ELXGB在保持高效率的同时不会牺牲模型准确性。 
## 论文速读 
### 论文方法 
### 方法描述

该论文提出了一种针对垂直联邦学习中的隐私保护方案，旨在在保证数据安全的前提下，实现高效的模型训练和推理服务。具体来说，该方案采用了两个算法：HE-based node split（HENS）和DP-based node split（DPNS），用于构建全局模型，并通过加密技术保护敏感信息。此外，该方案还设计了属性和方向的混淆算法，以进一步提高模型的安全性和准确性。

### 方法改进

与传统的垂直联邦学习方案相比，该方案的主要改进在于引入了加密技术和混淆算法，从而实现了更加严格的数据隐私保护。同时，该方案还采用了分布式计算的方式，使得模型训练和推理服务可以高效地完成。

### 解决的问题

该方案主要解决了垂直联邦学习中面临的隐私泄露问题，通过采用加密技术和混淆算法，有效地保护了用户数据的隐私性。此外，该方案还提高了模型的准确性和效率，为用户提供更好的服务体验。
 
##  
### 论文实验 
本文主要介绍了ELXGB算法在两个真实数据集上的性能评估，并与SecureBoost和PIVODL等代表性的方案进行了比较。具体来说，本文从模型准确性、计算成本和通信开销三个方面对ELXGB的性能进行了评估。

首先，在模型准确性方面，本文通过改变最大树数、最大树深度和隐私参数等超参数来比较ELXGB的表现。结果显示，ELXGB在全局提案下能够达到约83%和90%的平均准确率，与原始的XGBoost相比几乎达到了相同的精度。此外，随着隐私参数e的增加，ELXGB的模型精度变化很小，因此可以选择更安全的参数来训练高精度的模型。

其次，在计算成本方面，本文分析了数据对齐和模型训练的时间成本，并与SecureBoost和PIVODL等方案进行了比较。结果表明，ELXGB的数据对齐过程比Circuit/Quorum方案更加高效，其时间成本仅为后者的103ms左右。同时，ELXGB的模型训练时间也比其他方案要短，且不受模型结构的影响。在服务过程中，ELXGB的服务时间成本随着最大树数量的增加而增长缓慢，但受到模型结构的影响较大。

最后，在通信开销方面，本文评估了ELXGB的总通信开销，并与SecureBoost和PIVODL等方案进行了比较。结果表明，随着最大树数量的增加，ELXGB的通信开销保持稳定，而SecureBoost的通信开销则增长更快。另外，ELXGB的通信开销受训练数据量的影响，其中在Credit Card数据集上更高一些。

综上所述，ELXGB算法在模型准确性、计算成本和通信开销等方面都表现出了优异的性能，具有较高的实用价值。

![table_2](https://damo-moshicloud-test.oss-cn-hangzhou.aliyuncs.com/document/testcase/dingding/zhiwen_cases/1276309701896380416/1276309701896380416_cut_Table_2.png)

![table_3](https://damo-moshicloud-test.oss-cn-hangzhou.aliyuncs.com/document/testcase/dingding/zhiwen_cases/1276309701896380416/1276309701896380416_cut_Table_3.png)
 
##  
### 论文总结 
### 文章优点
该论文提出了一种高效且隐私保护的垂直联邦增强树框架ELXGB，能够实现高精度训练和推理，并在保证安全性和效率的前提下提供多种服务。该方案利用了Paillier加密技术和差分隐私技术来确保模型的安全性和隐私性，并采用了数据打包和密文压缩等优化策略来减少加密次数，提高效率。实验结果表明，ELXGB能够在保证高准确性的前提下，有效地抵抗模型反演攻击和属性推断攻击。

### 方法创新点
该论文的主要贡献在于提出了两种节点分裂算法，分别基于Paillier加密和差分隐私技术，以确保模型的安全性和隐私性。同时，还设计了两个模糊化算法，用于防止敏感信息泄漏并保护全局模型。此外，作者还采用了数据打包和密文压缩等优化策略来降低加密次数，提高效率。

### 未来展望
虽然ELXGB已经实现了高效的训练和推理，并且能够有效抵抗模型反演攻击和属性推断攻击，但仍然存在一些改进的空间。例如，可以进一步优化数据打包和密文压缩等技术，以提高效率；还可以探索其他加密技术的应用，如CKKS加密技术，以进一步提升安全性。此外，还可以考虑将ELXGB应用于更广泛的数据场景中，以满足不同领域的需求。
 
